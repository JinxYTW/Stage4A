{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import des libraries"
      ],
      "metadata": {
        "id": "4UgJNT25dZMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fundamentalvision/Deformable-DETR.git\n",
        "!cd /content/Deformable-DETR\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgGbMjP3hNK1",
        "outputId": "6ede1530-99b0-483c-8e39-32f2b49f0836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Deformable-DETR' already exists and is not an empty directory.\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Deformable-DETR\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i73AzQ0WiK-X",
        "outputId": "cdc00e2c-7a9c-4645-e2f7-568b82a46d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deformable-DETR\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.0.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation"
      ],
      "metadata": {
        "id": "NvVn41kTeUnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from pycocotools.coco import COCO\n",
        "from torchvision.datasets import CocoDetection\n",
        "from transformers import AutoImageProcessor, DeformableDetrForObjectDetection\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "Y_NNZH9neWdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Préparation du dataset"
      ],
      "metadata": {
        "id": "Fa4f6YjzeZTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/data.zip -d /content/custom_data_raw"
      ],
      "metadata": {
        "id": "PTjjmwcSfUX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "data/\n",
        "├── images/\n",
        "│   ├── train/\n",
        "│   │   ├── 000000000001.jpg\n",
        "│   │   ├── 000000000002.jpg\n",
        "│   │   ├── ...\n",
        "│   └── val/\n",
        "│       ├── 000000000001.jpg\n",
        "│       ├── 000000000002.jpg\n",
        "│       ├── ...\n",
        "├── annotations/\n",
        "│   ├── instances_train2017.json\n",
        "│   ├── instances_val2017.json\n"
      ],
      "metadata": {
        "id": "o3xNV2wAr4LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Répertoire d'origine pour les images et annotations\n",
        "raw_data_path_images = \"/content/custom_data_raw/images\"  # Images sont dans ce dossier\n",
        "raw_data_path_labels = \"/content/custom_data_raw/obj_train_data\"  # Annotations dans ce dossier\n",
        "\n",
        "# Obtenir toutes les images (jpg/png) présentes dans le dossier \"images\"\n",
        "images = [f for f in os.listdir(raw_data_path_images) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Split train/val (80% train, 20% val)\n",
        "train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Création des dossiers cible pour images et labels\n",
        "base_path = \"/content/custom_data\"\n",
        "\n",
        "\n",
        "os.makedirs(base_path + \"/images/train\", exist_ok=True)\n",
        "os.makedirs(base_path + \"/images/val\", exist_ok=True)\n",
        "os.makedirs(base_path + \"/labels/train\", exist_ok=True)\n",
        "os.makedirs(base_path + \"/labels/val\", exist_ok=True)\n",
        "\n",
        "def move_data(image_list, split):\n",
        "    for img_name in image_list:\n",
        "        # Déplacer l'image vers le bon dossier\n",
        "        src_img = os.path.join(raw_data_path_images, img_name)\n",
        "        dst_img = os.path.join(base_path, f\"images/{split}\", img_name)\n",
        "        shutil.copy(src_img, dst_img)\n",
        "\n",
        "        # Vérifier et déplacer l'annotation .txt correspondante\n",
        "        txt_name = img_name.rsplit('.', 1)[0] + '.txt'\n",
        "        txt_src = os.path.join(raw_data_path_labels, txt_name)\n",
        "        txt_dst = os.path.join(base_path, f\"labels/{split}\", txt_name)\n",
        "\n",
        "        if os.path.exists(txt_src):\n",
        "            shutil.copy(txt_src, txt_dst)\n",
        "        else:\n",
        "            print(f\"Pas d'annotation pour {img_name}\")\n",
        "\n",
        "# Appliquer le déplacement aux deux splits : train et val\n",
        "move_data(train_imgs, \"train\")\n",
        "move_data(val_imgs, \"val\")\n"
      ],
      "metadata": {
        "id": "meym5aIlfIYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "tile_size = 320\n",
        "overlap = 0\n",
        "splits = [\"train\", \"val\"]\n",
        "\n",
        "input_root = \"/content/custom_data\"\n",
        "output_root = \"/content/split_custom_data\"\n",
        "\n",
        "categories = []  # remplie dynamiquement\n",
        "\n",
        "def yolo_to_bbox(x_center, y_center, w, h, img_w, img_h):\n",
        "    x1 = (x_center - w / 2) * img_w\n",
        "    y1 = (y_center - h / 2) * img_h\n",
        "    w *= img_w\n",
        "    h *= img_h\n",
        "    return x1, y1, w, h  # Format COCO: x, y, width, height\n",
        "\n",
        "for split in splits:\n",
        "    image_id = 0\n",
        "    annotation_id = 0\n",
        "\n",
        "    input_img_dir = os.path.join(input_root, f\"images/{split}\")\n",
        "    input_lbl_dir = os.path.join(input_root, f\"labels/{split}\")\n",
        "    output_img_dir = os.path.join(output_root, f\"{split}/images\")\n",
        "    output_ann_path = os.path.join(output_root, f\"{split}/instances_{split}.json\")\n",
        "\n",
        "    os.makedirs(output_img_dir, exist_ok=True)\n",
        "\n",
        "    coco_dict = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": [],\n",
        "    }\n",
        "\n",
        "    label_set = set()\n",
        "    for filename in tqdm(os.listdir(input_img_dir), desc=f\"{split}\"):\n",
        "        if not filename.lower().endswith(('.jpg', '.png')):\n",
        "            continue\n",
        "\n",
        "        basename = os.path.splitext(filename)[0]\n",
        "        img_path = os.path.join(input_img_dir, filename)\n",
        "        label_path = os.path.join(input_lbl_dir, f\"{basename}.txt\")\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img_h, img_w = img.shape[:2]\n",
        "\n",
        "        annots = []\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, \"r\") as f:\n",
        "                for line in f.readlines():\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) == 5:\n",
        "                        cls, xc, yc, w, h = map(float, parts)\n",
        "                        annots.append((int(cls), *yolo_to_bbox(xc, yc, w, h, img_w, img_h)))\n",
        "                        label_set.add(int(cls))\n",
        "\n",
        "        step = tile_size - overlap\n",
        "        tile_id = 0\n",
        "\n",
        "        for y in range(0, img_h, step):\n",
        "            for x in range(0, img_w, step):\n",
        "                tile = img[y:y+tile_size, x:x+tile_size]\n",
        "                th, tw = tile.shape[:2]\n",
        "                if th < tile_size or tw < tile_size:\n",
        "                    continue\n",
        "\n",
        "                tile_fname = f\"{basename}_{tile_id}.jpg\"\n",
        "                tile_path = os.path.join(output_img_dir, tile_fname)\n",
        "                cv2.imwrite(tile_path, tile)\n",
        "\n",
        "                coco_dict[\"images\"].append({\n",
        "                    \"id\": image_id,\n",
        "                    \"width\": tile_size,\n",
        "                    \"height\": tile_size,\n",
        "                    \"file_name\": tile_fname,\n",
        "                })\n",
        "\n",
        "                for cls, x1, y1, w, h in annots:\n",
        "                    x2 = x1 + w\n",
        "                    y2 = y1 + h\n",
        "\n",
        "                    # Check if box overlaps the tile\n",
        "                    if x1 >= x + tile_size or x2 <= x or y1 >= y + tile_size or y2 <= y:\n",
        "                        continue\n",
        "\n",
        "                    box_x1 = max(0, x1 - x)\n",
        "                    box_y1 = max(0, y1 - y)\n",
        "                    box_x2 = min(tile_size, x2 - x)\n",
        "                    box_y2 = min(tile_size, y2 - y)\n",
        "\n",
        "                    box_w = box_x2 - box_x1\n",
        "                    box_h = box_y2 - box_y1\n",
        "\n",
        "                    if box_w < 1 or box_h < 1:\n",
        "                        continue\n",
        "\n",
        "                    coco_dict[\"annotations\"].append({\n",
        "                        \"id\": annotation_id,\n",
        "                        \"image_id\": image_id,\n",
        "                        \"category_id\": cls,\n",
        "                        \"bbox\": [box_x1, box_y1, box_w, box_h],\n",
        "                        \"area\": box_w * box_h,\n",
        "                        \"iscrowd\": 0,\n",
        "                    })\n",
        "                    annotation_id += 1\n",
        "\n",
        "                image_id += 1\n",
        "                tile_id += 1\n",
        "\n",
        "    coco_dict[\"categories\"] = [\n",
        "        {\"id\": cls, \"name\": str(cls), \"supercategory\": \"none\"}\n",
        "        for cls in sorted(label_set)\n",
        "    ]\n",
        "\n",
        "    with open(output_ann_path, \"w\") as f:\n",
        "        json.dump(coco_dict, f, indent=2)\n",
        "\n",
        "    print(f\"✅ COCO json sauvegardé dans : {output_ann_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LcHhIhffXem",
        "outputId": "3372643d-f6fc-4771-ff19-b77eeb8acbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 28/28 [00:04<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ COCO json sauvegardé dans : /content/split_custom_data/train/instances_train.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 7/7 [00:01<00:00,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ COCO json sauvegardé dans : /content/split_custom_data/val/instances_val.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/split_custom_data/train/images | head\n",
        "!ls /content/split_custom_data/train | grep json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7xY5PMxkveW",
        "outputId": "f4e3eb32-d71d-4738-c353-849698e82dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20221108_112523_0.jpg\n",
            "20221108_112523_10.jpg\n",
            "20221108_112523_11.jpg\n",
            "20221108_112523_12.jpg\n",
            "20221108_112523_13.jpg\n",
            "20221108_112523_14.jpg\n",
            "20221108_112523_15.jpg\n",
            "20221108_112523_16.jpg\n",
            "20221108_112523_17.jpg\n",
            "20221108_112523_18.jpg\n",
            "instances_train.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les étapes précèdentes sont là afin que le dataset possède le format voulu."
      ],
      "metadata": {
        "id": "C6rOH486tqBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ],
      "metadata": {
        "id": "F2E3DeUBmCEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/split_custom_data\"\n",
        "output_path = \"/content/output_olives\""
      ],
      "metadata": {
        "id": "AF-UyJ7hmD5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5QZmijvmHP_",
        "outputId": "62b0ed7e-7e86-4edd-ac4f-a4ea7d1a5e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmark.py  datasets\tengine.py  LICENSE  models     requirements.txt  util\n",
            "configs       docs\tfigs\t   main.py  README.md  tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.12.1 torchvision==0.13.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "919XnSpwmvL3",
        "outputId": "744b7779-297f-4147-b13f-3eacdf3cf0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.12.1 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.12.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --dataset_file coco \\\n",
        "  --coco_path {dataset_path} \\\n",
        "  --output_dir {output_path} \\\n",
        "  --batch_size 2 \\\n",
        "  --epochs 50 \\\n",
        "  --lr_drop 40 \\\n",
        "  --num_workers 2 \\\n",
        "  --resume \"\" \\\n",
        "  --with_box_refine \\\n",
        "  --two_stage\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Y5m_EqmPCP",
        "outputId": "807c3c74-6ba3-4bad-ce4c-e0a368a90959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/Deformable-DETR/main.py\", line 21, in <module>\n",
            "    import datasets\n",
            "  File \"/content/Deformable-DETR/datasets/__init__.py\", line 13, in <module>\n",
            "    from .coco import build as build_coco\n",
            "  File \"/content/Deformable-DETR/datasets/coco.py\", line 22, in <module>\n",
            "    from util.misc import get_local_rank, get_local_size\n",
            "  File \"/content/Deformable-DETR/util/misc.py\", line 32, in <module>\n",
            "    from torchvision.ops.misc import _NewEmptyTensorOp\n",
            "ImportError: cannot import name '_NewEmptyTensorOp' from 'torchvision.ops.misc' (/usr/local/lib/python3.11/dist-packages/torchvision/ops/misc.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sauvegarde"
      ],
      "metadata": {
        "id": "olA-E1YJiN2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'deformable_detr.pth')"
      ],
      "metadata": {
        "id": "7t0-lx57iQE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}